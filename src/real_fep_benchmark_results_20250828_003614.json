{
  "truthful_questions": {
    "benchmark": "TruthfulQA",
    "method": "Real FEP",
    "total_questions": 0,
    "analysis": {
      "error": "No results to analyze"
    },
    "raw_results": [],
    "processing_time": 1.0325095653533936
  },
  "misleading_questions": {
    "benchmark": "TruthfulQA",
    "method": "Real FEP",
    "total_questions": 0,
    "analysis": {
      "error": "No results to analyze"
    },
    "raw_results": [],
    "processing_time": 0.23920106887817383
  },
  "comparative_analysis": {
    "vfe_difference": 0,
    "detection_capability": false,
    "detection_strength": 0
  },
  "system_status": {
    "real_fep_components": true,
    "fep_system_available": true,
    "language_model_available": true,
    "benchmark_quality": "High"
  }
}